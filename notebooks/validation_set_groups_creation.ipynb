{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0b2dcc-98f9-4d69-9b9b-3a64991e6a39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e0b2dcc-98f9-4d69-9b9b-3a64991e6a39",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710146153036,
     "user_tz": -120,
     "elapsed": 33160,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "feaed6df-79d8-41a5-ddc8-7538e33978ea",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:13:29.328910Z",
     "start_time": "2024-03-16T08:13:28.633448Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from   tqdm            import tqdm\n",
    "import numpy           as np\n",
    "import pandas          as pd\n",
    "from   tqdm            import tqdm\n",
    "from   IPython.display import Audio\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd9a8f",
   "metadata": {
    "id": "51cd9a8f"
   },
   "source": [
    "<h1 style=\"background-color:#4CAF50;\"> <center> Create Validation groups for the first and second challenges  </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4addaa1",
   "metadata": {
    "id": "f4addaa1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147118234,
     "user_tz": -120,
     "elapsed": 273,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:13:34.152854Z",
     "start_time": "2024-03-16T08:13:34.149125Z"
    }
   },
   "outputs": [],
   "source": [
    "# reporoducability\n",
    "seed = 41\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffdd8b",
   "metadata": {
    "id": "65ffdd8b"
   },
   "source": [
    "<h1 style=\"background-color:#4CAF50;\"> <center> Load Train Dataset </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_folder = '/home/eyalshw/github/wzudemy/hakol/data/subset'\n",
    "print(os.path.exists(data_folder))\n",
    "audio_files_path  = os.path.join(data_folder, \"wav_files_subset\")\n",
    "print(os.path.exists(audio_files_path))\n",
    "challenge_folder = os.path.join(data_folder, \"challenge\")\n",
    "if not os.path.exists(challenge_folder):\n",
    "    os.makedirs(challenge_folder)\n",
    "# TODO: Place the file: groups_challenge.csv in challenge_folder"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jYcpFDHp1Sc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710146180122,
     "user_tz": -120,
     "elapsed": 334,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "0d2f8ea8-5969-40bd-d6a0-6e87e81791ab",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:15:46.726222Z",
     "start_time": "2024-03-16T08:15:46.723098Z"
    }
   },
   "id": "7jYcpFDHp1Sc",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6126fd02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "6126fd02",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147337828,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "28a23555-43cd-49d8-e3ac-a85ac0cd00fc",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:15:48.660068Z",
     "start_time": "2024-03-16T08:15:48.646642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances: 74\n"
     ]
    },
    {
     "data": {
      "text/plain": "  language         file  speaker  noise_type\n0  russian  2006849.wav     3191        comm\n1  russian  3018610.wav     3191       clean\n2  russian  7608580.wav     3191  background\n3  russian  4426066.wav     3191        comm\n4  russian  8924221.wav     3191  background",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>file</th>\n      <th>speaker</th>\n      <th>noise_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>russian</td>\n      <td>2006849.wav</td>\n      <td>3191</td>\n      <td>comm</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>russian</td>\n      <td>3018610.wav</td>\n      <td>3191</td>\n      <td>clean</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>russian</td>\n      <td>7608580.wav</td>\n      <td>3191</td>\n      <td>background</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>russian</td>\n      <td>4426066.wav</td>\n      <td>3191</td>\n      <td>comm</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>russian</td>\n      <td>8924221.wav</td>\n      <td>3191</td>\n      <td>background</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_CSV = os.path.join(data_folder,\"hackathon_train_subset.csv\")\n",
    "# in the hackathon don't forget to unmark to the line below\n",
    "# TRAIN_CSV = os.path.join(data_folder,\"hackathon_train.csv\")\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print(f\"Number of utterances: {train_df.shape[0]}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e020eb3",
   "metadata": {
    "cellView": "form",
    "id": "5e020eb3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147338232,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:15:58.403083Z",
     "start_time": "2024-03-16T08:15:58.399426Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Let's define some helper methods\n",
    "def get_speaker_lang(df, speaker):\n",
    "    return df[df.speaker == speaker]['language'].iloc[0]\n",
    "\n",
    "def get_utterance_lang(df, file):\n",
    "    return df[df.file == file]['language'].iloc[0]\n",
    "\n",
    "def get_utterance_noise_type(df, file):\n",
    "    return df[df.file == file]['noise_type'].iloc[0]\n",
    "\n",
    "def get_spk_to_utt(df):\n",
    "    # Creta a dictionary of speaker to utterances\n",
    "    spk_to_utts = dict()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_path = row['file']\n",
    "        spk       = row['speaker']\n",
    "        file_path = os.path.join(audio_files_path, file_path)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Found invalid file: {file_path}\")\n",
    "\n",
    "        if spk not in spk_to_utts:\n",
    "            spk_to_utts[spk] = [file_path]\n",
    "        else:\n",
    "            spk_to_utts[spk].append(file_path)\n",
    "    return spk_to_utts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4265c79-e160-4ded-b6b9-13473a74dd3a",
   "metadata": {
    "id": "f4265c79-e160-4ded-b6b9-13473a74dd3a"
   },
   "source": [
    "<h1 style=\"background-color:#4CAF50;\"> <center> Split to train and validation </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa2173e-0dc4-4045-b574-2eb94db2d8c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa2173e-0dc4-4045-b574-2eb94db2d8c8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147339087,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "5b5d0617-3a46-4c6a-f767-0f5be5dfa6e1",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:02.475200Z",
     "start_time": "2024-03-16T08:21:02.468597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((74, 4), (14, 4), (60, 4))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: You should split the train to train/validation and run the rest of this script on the validation only\n",
    "# We split here by the speaker but there could be better ways to split...\n",
    "\n",
    "# Get unique speakers\n",
    "unique_speakers = train_df['speaker'].unique()\n",
    "\n",
    "# Split the unique speakers into train and validation sets\n",
    "train_speakers, validation_speakers = train_test_split(unique_speakers, test_size=0.8, random_state=seed)\n",
    "\n",
    "# Filter dataframe based on the split speakers\n",
    "train_df_new = train_df[train_df['speaker'].isin(train_speakers)]\n",
    "validation_df = train_df[train_df['speaker'].isin(validation_speakers)]\n",
    "\n",
    "train_df.shape, train_df_new.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:29.321257Z",
     "start_time": "2024-03-16T08:21:29.318859Z"
    }
   },
   "id": "aa3ea20123ddd77a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d68db63e-4317-4e0a-9883-ffccb0f79379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d68db63e-4317-4e0a-9883-ffccb0f79379",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147339783,
     "user_tz": -120,
     "elapsed": 423,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "5c79dddc-86f7-4179-ad9b-6d74c51ab35f",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:31.903282Z",
     "start_time": "2024-03-16T08:21:31.895519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of speakers in validation set: 4\n"
     ]
    }
   ],
   "source": [
    "spk_to_utts = get_spk_to_utt(validation_df)\n",
    "\n",
    "speakers  = set(spk_to_utts.keys())\n",
    "\n",
    "print(f\"Amount of speakers in validation set: {len(speakers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e80ca",
   "metadata": {
    "id": "463e80ca"
   },
   "source": [
    "<h1 style=\"background-color:#4CAF50;\"> <center> Challenge Validation: Create Random Anchors and Groups </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaaf589",
   "metadata": {
    "id": "fdaaf589"
   },
   "source": [
    "Creating the dataset:\n",
    "1. Choose the anchor speakers:</br>\n",
    "    Choose them randomly as long as they have at least 2 utterances per speaker.</br>\n",
    "  \n",
    "2. Create the groups. Each group creation gets an anchor as param:</br>\n",
    "    2.1 Select a file as the anchor utterance</br>\n",
    "    2.2 Get another utterance from the anchor speaker and add it to the group utterances</br>\n",
    "    2.3 Randomly decide the number of utterences in the group</br>\n",
    "    2.4 Select the other utterances (from the same languages) in the group</br>\n",
    "    2.5 Shuffle the group utterances before returning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6842ea",
   "metadata": {
    "id": "9c6842ea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147340176,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:37.033268Z",
     "start_time": "2024-03-16T08:21:37.028830Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_GROUPS_TO_CREATE = len(speakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-size: larger;\"> Define some helper methods:"
   ],
   "metadata": {
    "id": "JugpgdlkuNgX"
   },
   "id": "JugpgdlkuNgX"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b837a57a",
   "metadata": {
    "cellView": "form",
    "id": "b837a57a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147340924,
     "user_tz": -120,
     "elapsed": 8,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:37.818550Z",
     "start_time": "2024-03-16T08:21:37.813593Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def choose_anchor_utt(speaker, spk_to_utts):\n",
    "    \"\"\"\n",
    "    Selects an anchor utterance and another random utterance for a given speaker.\n",
    "\n",
    "    Parameters:\n",
    "    - speaker: The identifier for the speaker of interest.\n",
    "    - spk_to_utts: A dictionary mapping each speaker to a list of their utterances (file paths).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        - speaker: The identifier of the speaker.\n",
    "        - anchor_audio_basename: The base name of the anchor audio file (without folder path).\n",
    "        - same_speaker_utt_basename: The base name of another utterance from the same speaker.\n",
    "    \"\"\"\n",
    "    anchor_audio = random.choice(spk_to_utts[speaker])\n",
    "\n",
    "    # get another utterance from the same speaker\n",
    "    all_speaker_utt = spk_to_utts[speaker]\n",
    "\n",
    "    all_speaker_utt.remove(anchor_audio)\n",
    "\n",
    "    random.shuffle(all_speaker_utt)\n",
    "    same_speaker_utt = all_speaker_utt[0]\n",
    "\n",
    "    return speaker, os.path.basename(anchor_audio), os.path.basename(same_speaker_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad044476",
   "metadata": {
    "cellView": "form",
    "id": "ad044476",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147342340,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:38.035613Z",
     "start_time": "2024-03-16T08:21:38.030095Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def create_group(df, anchor_speaker, spk_to_utts):\n",
    "    \"\"\"\n",
    "    Creates a group of audio files based on a given anchor speaker. The group is formed by selecting\n",
    "    an anchor utterance from the anchor speaker and additional utterances from different speakers\n",
    "    that share the same language as the anchor.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing metadata about the audio files, including speaker, file path, language, and noise type.\n",
    "    - anchor_speaker: The identifier for the anchor speaker.\n",
    "    - spk_to_utts: A dictionary mapping each speaker to their utterances (audio file paths).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing information about the created group, including:\n",
    "        - group_audio_files: A list of the base names of the audio files in the group.\n",
    "        - group_audio_speaker: A list of speaker identifiers corresponding to each file in the group.\n",
    "        - anchor_speaker: The identifier of the anchor speaker.\n",
    "        - anchor_audio: The base name of the anchor audio file.\n",
    "        - anchor_type: The noise type of the anchor audio file.\n",
    "        - same_speaker_utt: The base name of another utterance from the anchor speaker.\n",
    "        - group_audio_type: A list of noise types corresponding to each audio file in the group.\n",
    "\n",
    "    The function first selects an anchor utterance for the anchor speaker and another utterance from the\n",
    "    same speaker. It then identifies additional speakers who speak the same language as the anchor speaker\n",
    "    and randomly selects utterances from these speakers to form the group.\n",
    "    \"\"\"\n",
    "\n",
    "    speakers = list(spk_to_utts.keys())\n",
    "\n",
    "    # Choose an anchor audio file for the anchor speaker\n",
    "    anchor_speaker, anchor_audio, same_speaker_utt = choose_anchor_utt(anchor_speaker, spk_to_utts)\n",
    "\n",
    "    # Get the anchor's language\n",
    "    anchor_lang = get_speaker_lang(df, anchor_speaker)\n",
    "    anchor_type = get_utterance_noise_type(df, anchor_audio)\n",
    "\n",
    "    # Remove anchor speaker temporarily\n",
    "    speakers.remove(anchor_speaker)\n",
    "\n",
    "    group_audio_files   = []\n",
    "    group_audio_speaker = []\n",
    "    group_audio_type    = []\n",
    "\n",
    "    # Randomly decide the number of files in the group\n",
    "    num_files_in_group = random.randint(5, 20)\n",
    "\n",
    "    group_audio_files.append(same_speaker_utt)\n",
    "    group_audio_speaker.append(anchor_speaker)\n",
    "    group_audio_type.append(get_utterance_noise_type(df, same_speaker_utt))\n",
    "\n",
    "    num_files_in_group -= 1  # Decrement since we added one from the anchor speaker\n",
    "\n",
    "    # Randomly select speakers from the same language\n",
    "    curr_speakers = set(df[(df.language == anchor_lang) & (df.speaker != anchor_speaker)]['speaker'].values.tolist())\n",
    "\n",
    "    selected_speakers = random.sample(list(curr_speakers), min(num_files_in_group, len(curr_speakers)))\n",
    "\n",
    "    for speaker in selected_speakers:\n",
    "        group_utt = random.choice(spk_to_utts[speaker])\n",
    "        group_audio_files.append(group_utt)\n",
    "        group_audio_speaker.append(speaker)\n",
    "        group_audio_type.append(get_utterance_noise_type(df, os.path.basename(group_utt)))\n",
    "\n",
    "    group_audio_files = [os.path.basename(f) for f in group_audio_files]\n",
    "    combined_lists = list(zip(group_audio_files, group_audio_speaker))\n",
    "    random.shuffle(combined_lists)\n",
    "    group_audio_files, group_audio_speaker = zip(*combined_lists)\n",
    "    return group_audio_files, group_audio_speaker, anchor_speaker, anchor_audio, anchor_type, same_speaker_utt, group_audio_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f7baeb",
   "metadata": {
    "cellView": "form",
    "id": "b1f7baeb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147343284,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:38.244188Z",
     "start_time": "2024-03-16T08:21:38.237025Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def create_dataset(df, spk_to_utts, num_groups=NUM_GROUPS_TO_CREATE):\n",
    "    \"\"\"\n",
    "    Generates dataset of groups where each group contains an anchor audio file\n",
    "    and additional audio files.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing audio file metadata, including speaker IDs, file paths, languages, and noise types.\n",
    "    - spk_to_utts: Dictionary mapping speaker IDs to their utterances (list of audio file paths).\n",
    "    - num_groups: The desired number of groups to create in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - groups_df: A pandas DataFrame with columns detailing each group's composition, including the group ID, anchor file,\n",
    "                 anchor speaker, group files, speakers for each file in the group, and the target label (file from the\n",
    "                 same speaker as the anchor).\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    # Filter speakers to only those with at least two audio files\n",
    "    speakers_with_at_least_two_utts = [speaker for speaker in speakers if len(spk_to_utts[speaker]) >= 2]\n",
    "\n",
    "    # Ensure there are enough speakers to meet the num_groups requirement\n",
    "    if len(speakers_with_at_least_two_utts) >= num_groups:\n",
    "        # Directly sample from the filtered list of speakers\n",
    "        anchor_speakers = random.sample(speakers_with_at_least_two_utts, num_groups)\n",
    "    else:\n",
    "        raise ValueError(f\"Not enough speakers with at least two utterances to form {num_groups} groups.\")\n",
    "\n",
    "    for i in range(num_groups):\n",
    "        anchor = anchor_speakers[i]\n",
    "        # create the group for this anchor\n",
    "        group, group_audio_speaker, anchor_speaker_id, anchor_utt, anchor_type, label, group_audio_type = create_group(df, anchor, spk_to_utts)\n",
    "\n",
    "        dataset.append({\n",
    "            'group_index'        : i,\n",
    "            'group'              : group,\n",
    "            'group_audio_speaker': group_audio_speaker,\n",
    "            'group_audio_type'   : group_audio_type,\n",
    "            'anchor_speaker'     : anchor_speaker_id,\n",
    "            'anchor'             : anchor_utt,\n",
    "            'anchor_type'             : anchor_type,\n",
    "            'label'              : label\n",
    "        })\n",
    "\n",
    "    # create a new dataframe with columns: group_id, anchor_file, group_file, group_label, group_audio_type\n",
    "    rows = []\n",
    "    for group in dataset:\n",
    "        group_index      = group['group_index']\n",
    "        anchor_file      = os.path.basename(group['anchor'])\n",
    "        anchor_speaker   = group['anchor_speaker']\n",
    "        anchor_type   = group['anchor_type']\n",
    "        group_label      = os.path.basename(group['label'])\n",
    "\n",
    "        for i, f in enumerate(group['group']):\n",
    "            group_file = os.path.basename(f)\n",
    "            group_audio_speaker = group['group_audio_speaker'][i]\n",
    "            group_audio_type    = group['group_audio_type'][i]\n",
    "            row = {'group_id': group_index, 'group_audio_speaker' : group_audio_speaker, 'group_label': group_label, 'anchor_file': anchor_file, 'anchor_speaker': anchor_speaker, 'anchor_type': anchor_type, 'group_file':group_file, 'group_audio_type':group_audio_type}\n",
    "            rows.append(row)\n",
    "\n",
    "    groups_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Reorder the columns:\n",
    "    # group_id:            The ID of the group\n",
    "    # anchor_file:         The file which is the anchor\n",
    "    # anchor_speaker:      The speaker id of the person speaking in the anchor_file\n",
    "    # group_file:          A file in the group\n",
    "    # group_audio_speaker: The speaker is that is speaking in the group_file\n",
    "    # group_audio_type:    The noise type of this group file\n",
    "    # group_label:         The label we want to predict, the name of the group_file in which the speaker is the same as the anchor_file\n",
    "\n",
    "    groups_df = groups_df[[\"group_id\", \"anchor_file\", \"anchor_speaker\", \"anchor_type\", \"group_file\", \"group_audio_speaker\", \"group_audio_type\", \"group_label\"]]\n",
    "\n",
    "    return groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902fbb7-8789-40b5-94ab-559143cbe217",
   "metadata": {
    "id": "0902fbb7-8789-40b5-94ab-559143cbe217"
   },
   "source": [
    "<span style=\"font-size: larger;\"> Create the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_GROUPS_TO_CREATE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:39.315014Z",
     "start_time": "2024-03-16T08:21:39.309987Z"
    }
   },
   "id": "5b09714a7df54bfe",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fc4b9e0",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "4fc4b9e0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710147344437,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "outputId": "3e14dc48-04ea-443e-96fc-5f2621426fc0",
    "ExecuteTime": {
     "end_time": "2024-03-16T08:21:40.267787Z",
     "start_time": "2024-03-16T08:21:40.254543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   group_id  anchor_file  anchor_speaker anchor_type   group_file  \\\n0         0  7890459.wav            4177       clean  1029247.wav   \n1         0  7890459.wav            4177       clean  1834021.wav   \n2         1  6541755.wav             928        comm  3081309.wav   \n3         2  5988172.wav            2533  background  0731480.wav   \n4         2  5988172.wav            2533  background  5656834.wav   \n5         3  9062151.wav            3363       clean  2509805.wav   \n\n   group_audio_speaker group_audio_type  group_label  \n0                 2533       background  1834021.wav  \n1                 4177            clean  1834021.wav  \n2                  928       background  3081309.wav  \n3                 2533       background  0731480.wav  \n4                 4177            clean  0731480.wav  \n5                 3363             comm  2509805.wav  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group_id</th>\n      <th>anchor_file</th>\n      <th>anchor_speaker</th>\n      <th>anchor_type</th>\n      <th>group_file</th>\n      <th>group_audio_speaker</th>\n      <th>group_audio_type</th>\n      <th>group_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7890459.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1029247.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>1834021.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7890459.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1834021.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1834021.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6541755.wav</td>\n      <td>928</td>\n      <td>comm</td>\n      <td>3081309.wav</td>\n      <td>928</td>\n      <td>background</td>\n      <td>3081309.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5988172.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>0731480.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>0731480.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>5988172.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>5656834.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>0731480.wav</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>9062151.wav</td>\n      <td>3363</td>\n      <td>clean</td>\n      <td>2509805.wav</td>\n      <td>3363</td>\n      <td>comm</td>\n      <td>2509805.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df = create_dataset(validation_df, spk_to_utts, NUM_GROUPS_TO_CREATE)\n",
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f101463c-dc92-41e4-ae09-6649f0390ad1",
   "metadata": {
    "id": "f101463c-dc92-41e4-ae09-6649f0390ad1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1710146479808,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "Shiry Yonash",
      "userId": "13226437010615716886"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-16T08:31:44.116242Z",
     "start_time": "2024-03-16T08:31:44.112062Z"
    }
   },
   "outputs": [],
   "source": [
    "groups_df.to_csv(os.path.join(challenge_folder, 'groups_challenge_validation.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/eyalshw/github/wzudemy/hakol/data/subset/challenge'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_folder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T08:31:02.391670Z",
     "start_time": "2024-03-16T08:31:02.388884Z"
    }
   },
   "id": "c61dde7f17b3fe4c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   group_id  anchor_file  anchor_speaker anchor_type   group_file  \\\n0         0  7890459.wav            4177       clean  1029247.wav   \n1         0  7890459.wav            4177       clean  1834021.wav   \n2         1  6541755.wav             928        comm  3081309.wav   \n3         2  5988172.wav            2533  background  0731480.wav   \n4         2  5988172.wav            2533  background  5656834.wav   \n5         3  9062151.wav            3363       clean  2509805.wav   \n\n   group_audio_speaker group_audio_type  group_label  \n0                 2533       background  1834021.wav  \n1                 4177            clean  1834021.wav  \n2                  928       background  3081309.wav  \n3                 2533       background  0731480.wav  \n4                 4177            clean  0731480.wav  \n5                 3363             comm  2509805.wav  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group_id</th>\n      <th>anchor_file</th>\n      <th>anchor_speaker</th>\n      <th>anchor_type</th>\n      <th>group_file</th>\n      <th>group_audio_speaker</th>\n      <th>group_audio_type</th>\n      <th>group_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7890459.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1029247.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>1834021.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7890459.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1834021.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>1834021.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6541755.wav</td>\n      <td>928</td>\n      <td>comm</td>\n      <td>3081309.wav</td>\n      <td>928</td>\n      <td>background</td>\n      <td>3081309.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5988172.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>0731480.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>0731480.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>5988172.wav</td>\n      <td>2533</td>\n      <td>background</td>\n      <td>5656834.wav</td>\n      <td>4177</td>\n      <td>clean</td>\n      <td>0731480.wav</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>9062151.wav</td>\n      <td>3363</td>\n      <td>clean</td>\n      <td>2509805.wav</td>\n      <td>3363</td>\n      <td>comm</td>\n      <td>2509805.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T08:31:06.665868Z",
     "start_time": "2024-03-16T08:31:06.660088Z"
    }
   },
   "id": "e86918a498abdd3",
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
